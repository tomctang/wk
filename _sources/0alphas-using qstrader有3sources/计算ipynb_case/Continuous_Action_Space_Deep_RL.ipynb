{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5655db2",
   "metadata": {},
   "source": [
    "The code provided consists of two main components: the **TradingEnvironment class** and the **main()** function. The TradingEnvironment class is a custom environment that handles stock or cryptocurrency data, and the main() function is responsible for loading data, creating the environment, and training the TD3 model.\n",
    "\n",
    "**TradingEnvironment class:**\n",
    "\n",
    "The TradingEnvironment class extends the gym.Env class from the OpenAI Gym library. It is designed to simulate a trading environment where an agent interacts with stock or cryptocurrency data to learn a trading strategy. Key components of this class include:\n",
    "\n",
    "-    __init__: Initializes the environment with the input data and sets up the action and observation spaces.\n",
    "-    reset: Resets the environment to its initial state.\n",
    "-    step: Performs a trading action, updates the environment state, and returns the next observation, reward, and a flag indicating whether the episode has ended.\n",
    "-    _next_observation: Returns the next observation (a window of stock/cryptocurrency data).\n",
    "-    _execute_action: Executes the trading action based on the input action and updates the current balance and stock_owned.\n",
    "-    _calculate_reward: Calculates the reward as the difference between the current portfolio value and the initial balance.\n",
    "-    _is_done: Determines if the episode has ended by checking if the current step is equal to or greater than the length of the data minus the window_size.\n",
    "\n",
    "\n",
    "**main() function:**\n",
    "\n",
    "The main() function is responsible for the following tasks:\n",
    "\n",
    "-    Loading stock/cryptocurrency data from a CSV file.\n",
    "-    Preprocessing the data by setting the 'Date' column as the index.\n",
    "-    Creating the custom TradingEnvironment instance using the preprocessed data.\n",
    "-    Defining the action noise for exploration during the learning process.\n",
    "-    Creating the TD3 model with the custom environment and action noise.\n",
    "-    Training the model for a specified number of timesteps.\n",
    "-    Saving the trained model.\n",
    "\n",
    "The TD3 model uses a continuous action space, allowing it to output both the position (buy or sell) and the number of trading shares. The model learns the optimal trading strategy by interacting with the TradingEnvironment, executing actions, and observing the rewards. The NormalActionNoise is used to introduce exploration during the learning process, enabling the agent to explore different trading strategies before converging to an optimal one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f3efec7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "import gym\n",
    "from gym import spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfdf6bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingEnvironment(gym.Env):\n",
    "    def __init__(self, data, initial_balance=10000, window_size=10):\n",
    "        super(TradingEnvironment, self).__init__()\n",
    "\n",
    "        self.data = data\n",
    "        self.initial_balance = initial_balance\n",
    "        self.window_size = window_size\n",
    "        self.current_step = 0\n",
    "        self.current_balance = initial_balance\n",
    "        self.stock_owned = 0\n",
    "        self.stock_price = 0\n",
    "\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(2,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(window_size, 4), dtype=np.float32)\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.current_balance = self.initial_balance\n",
    "        self.stock_owned = 0\n",
    "        self.stock_price = 0\n",
    "        return self._next_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        self.current_step += 1\n",
    "        self.stock_price = self.data.loc[self.current_step, \"Close\"]\n",
    "\n",
    "        self._execute_action(action)\n",
    "\n",
    "        reward = self._calculate_reward()\n",
    "        done = self._is_done()\n",
    "\n",
    "        return self._next_observation(), reward, done, {}\n",
    "\n",
    "    def _next_observation(self):\n",
    "        return self.data[self.current_step : self.current_step + self.window_size]\n",
    "\n",
    "    def _execute_action(self, action):\n",
    "        position_action, quantity_action = action\n",
    "\n",
    "        if position_action < 0:\n",
    "            # Sell\n",
    "            self.stock_owned = max(self.stock_owned - int(quantity_action * self.stock_owned), 0)\n",
    "        elif position_action > 0:\n",
    "            # Buy\n",
    "            num_shares_to_buy = int(quantity_action * self.current_balance / self.stock_price)\n",
    "            self.stock_owned += num_shares_to_buy\n",
    "            self.current_balance -= num_shares_to_buy * self.stock_price\n",
    "\n",
    "    def _calculate_reward(self):\n",
    "        portfolio_value = self.current_balance + self.stock_owned * self.stock_price\n",
    "        reward = portfolio_value - self.initial_balance\n",
    "        return reward\n",
    "\n",
    "    def _is_done(self):\n",
    "        return self.current_step >= len(self.data) - self.window_size - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fde1b978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "def preprocess_data(data):\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data.set_index('Date', inplace=True)\n",
    "    return data\n",
    "\n",
    "def main():\n",
    "    stock_file_path = 'path/to/your/stock/data.csv'  #provide path to your data file here\n",
    "    stock_data = load_data(stock_file_path)\n",
    "    stock_data = preprocess_data(stock_data)\n",
    "    \n",
    "    env = TradingEnvironment(stock_data)\n",
    "\n",
    "    n_actions = env.action_space.shape[-1]\n",
    "    action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "    model = TD3('MlpPolicy', env, action_noise=action_noise, verbose=1)\n",
    "    model.learn(total_timesteps=100000)\n",
    "    model.save(\"td3_trading_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3497107",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd2d81e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
